

- implement accumulating gradients

- fix error

- make it reproducible (added seeds for learner and actor) # commented out

- reorganize everything
    (change mask_prob back to 0.20)
    (reverse load pretrained embeddings)
    (reverse get_gradients)


TODO:


- reorganize everything (today)

    (check all hyper-parameters)
    (reverse get_context)
    (reverse env prices)

    (consider add improvements from lucidrains)
    (compare with gelu and without gelu for transformer output)

- batched actor with varying epsilon (for inference and multiple env) (today)

- start main training (today)

